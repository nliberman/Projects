{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest regressor, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop the scraping sites into the function loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ny61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "ny181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=New+York&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "\n",
    "sf61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "sf181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=San+Francisco%2C+CA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "\n",
    "dc61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "dc181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=Washington+City%2C+DC&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "\n",
    "bos61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "bos181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=Boston%2C+MA&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "\n",
    "hou61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "hou181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=Houston%2C+TX&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "\n",
    "chi61_80 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2461k-%2480k&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi81_100 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%2481%2C000+-+%24100%2C000&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi101_120 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24101%2C000+-+%24120%2C000&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi121_140 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24121%2C000+-+%24140%2C000&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi141_160 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24141%2C000+-+%24160%2C000&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi161_180 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24161%2C000+-+%24180%2C000&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n",
    "chi181_200 = 'https://www.indeed.com/jobs?as_and=data+scientist&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&jt=all&st=&salary=%24181K-%24200K&radius=25&l=Chicago%2C+IL&fromage=any&limit=200&sort=&psf=advsrch'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract each item: location, company, job, and salary.¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [['Title','Location', 'City', 'Company', 'Salary_Range', 'Salary_Avg', 'Summary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_all(url, city, sal_range, sal_average):\n",
    "    html = urllib.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, 'html.parser', from_encoding=\"utf-8\")\n",
    "    ## locate the job posting block\n",
    "    for i in soup.find_all('div',{'class':' row result'}):\n",
    "        title = i.find('a').text\n",
    "        location = i.find('span',{'class':'location'}).text\n",
    "        company = i.find('span',{'class':'company'}).text\n",
    "        salary_range = sal_range\n",
    "        salary_avg = sal_average\n",
    "        summary = i.find('span',{'class':'summary'}).text\n",
    "        df.loc[len(df)] = [title,location, city, company,salary_range,salary_avg,summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrape_all(ny61_80, 'NY', '61k-80k', 70.5)\n",
    "scrape_all(ny81_100, 'NY', '81k-100k', 90.5)\n",
    "scrape_all(ny101_120, 'NY', '101k-120k', 110.5)\n",
    "scrape_all(ny121_140, 'NY', '121k-140k', 130.5)\n",
    "scrape_all(ny141_160, 'NY', '141k-160k', 150.5)\n",
    "scrape_all(ny161_180, 'NY', '161k-180k', 170.5)\n",
    "scrape_all(ny181_200, 'NY', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrape_all(sf61_80, 'SF', '61k-80k', 70.5)\n",
    "scrape_all(sf81_100, 'SF', '81k-100k', 90.5)\n",
    "scrape_all(sf101_120, 'SF', '101k-120k', 110.5)\n",
    "scrape_all(sf121_140, 'SF', '121k-140k', 130.5)\n",
    "scrape_all(sf141_160, 'SF', '141k-160k', 150.5)\n",
    "scrape_all(sf161_180, 'SF', '161k-180k', 170.5)\n",
    "scrape_all(sf181_200, 'SF', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_all(dc61_80, 'DC', '61k-80k', 70.5)\n",
    "scrape_all(dc81_100, 'DC', '81k-100k', 90.5)\n",
    "scrape_all(dc101_120, 'DC', '101k-120k', 110.5)\n",
    "scrape_all(dc121_140, 'DC', '121k-140k', 130.5)\n",
    "scrape_all(dc141_160, 'DC', '141k-160k', 150.5)\n",
    "scrape_all(dc161_180, 'DC', '161k-180k', 170.5)\n",
    "scrape_all(dc181_200, 'DC', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrape_all(bos61_80, 'BOS', '61k-80k', 70.5)\n",
    "scrape_all(bos81_100, 'BOS', '81k-100k', 90.5)\n",
    "scrape_all(bos101_120, 'BOS', '101k-120k', 110.5)\n",
    "scrape_all(bos121_140, 'BOS', '121k-140k', 130.5)\n",
    "scrape_all(bos141_160, 'BOS', '141k-160k', 150.5)\n",
    "scrape_all(bos161_180, 'BOS', '161k-180k', 170.5)\n",
    "scrape_all(bos181_200, 'BOS', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_all(hou61_80, 'HOU', '61k-80k', 70.5)\n",
    "scrape_all(hou81_100, 'HOU', '81k-100k', 90.5)\n",
    "scrape_all(hou101_120, 'HOU', '101k-120k', 110.5)\n",
    "scrape_all(hou121_140, 'HOU', '121k-140k', 130.5)\n",
    "scrape_all(hou141_160, 'HOU', '141k-160k', 150.5)\n",
    "scrape_all(hou161_180, 'HOU', '161k-180k', 170.5)\n",
    "scrape_all(hou181_200, 'HOU', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_all(chi61_80, 'CHI', '61k-80k', 70.5)\n",
    "scrape_all(chi81_100, 'CHI', '81k-100k', 90.5)\n",
    "scrape_all(chi101_120, 'CHI', '101k-120k', 110.5)\n",
    "scrape_all(chi121_140, 'CHI', '121k-140k', 130.5)\n",
    "scrape_all(chi141_160, 'CHI', '141k-160k', 150.5)\n",
    "scrape_all(chi161_180, 'CHI', '161k-180k', 170.5)\n",
    "scrape_all(chi181_200, 'CHI', '181k-200k', 190.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Company'] = df['Company'].str.strip('\\n')\n",
    "df['Summary'] = df['Summary'].str.strip('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>Analytics Go-To-Market Account Lead, Retail In...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>Understanding of analytics roles and responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>Senior Engineer - Site Reliability</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Civis Analytics</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>Engineers collaborate across departments with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Evanston, IL 60201</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>The team is taking a concept that they’ve used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>Data Scientists and Quantitative Researchers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Optiver</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Data Scientists and Quantitative Researchers. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>Vice President - Global Digital-Analytics</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Insights &amp; Data. (big data, enterprise content...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title            Location  \\\n",
       "2316  Analytics Go-To-Market Account Lead, Retail In...         Chicago, IL   \n",
       "2317                 Senior Engineer - Site Reliability         Chicago, IL   \n",
       "2318                                    DevOps Engineer  Evanston, IL 60201   \n",
       "2319       Data Scientists and Quantitative Researchers         Chicago, IL   \n",
       "2320          Vice President - Global Digital-Analytics         Chicago, IL   \n",
       "\n",
       "     City                     Company Salary_Range  Salary_Avg  \\\n",
       "2316  CHI                   Accenture    141k-160k       150.5   \n",
       "2317  CHI             Civis Analytics    141k-160k       150.5   \n",
       "2318  CHI          Jobspring Partners    141k-160k       150.5   \n",
       "2319  CHI                     Optiver    161k-180k       170.5   \n",
       "2320  CHI                   Capgemini    161k-180k       170.5   \n",
       "\n",
       "                                                Summary  \n",
       "2316  Understanding of analytics roles and responsib...  \n",
       "2317  Engineers collaborate across departments with ...  \n",
       "2318  The team is taking a concept that they’ve used...  \n",
       "2319  Data Scientists and Quantitative Researchers. ...  \n",
       "2320  Insights & Data. (big data, enterprise content...  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>Analytics Go-To-Market Account Lead, Retail In...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>Understanding of analytics roles and responsib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>Senior Engineer - Site Reliability</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Civis Analytics</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>Engineers collaborate across departments with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Evanston, IL 60201</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>The team is taking a concept that they’ve used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>Data Scientists and Quantitative Researchers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Optiver</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Data Scientists and Quantitative Researchers. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>Vice President - Global Digital-Analytics</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Insights &amp; Data. (big data, enterprise content...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title            Location  \\\n",
       "2316  Analytics Go-To-Market Account Lead, Retail In...         Chicago, IL   \n",
       "2317                 Senior Engineer - Site Reliability         Chicago, IL   \n",
       "2318                                    DevOps Engineer  Evanston, IL 60201   \n",
       "2319       Data Scientists and Quantitative Researchers         Chicago, IL   \n",
       "2320          Vice President - Global Digital-Analytics         Chicago, IL   \n",
       "\n",
       "     City                     Company Salary_Range  Salary_Avg  \\\n",
       "2316  CHI                   Accenture    141k-160k       150.5   \n",
       "2317  CHI             Civis Analytics    141k-160k       150.5   \n",
       "2318  CHI          Jobspring Partners    141k-160k       150.5   \n",
       "2319  CHI                     Optiver    161k-180k       170.5   \n",
       "2320  CHI                   Capgemini    161k-180k       170.5   \n",
       "\n",
       "                                                Summary  \n",
       "2316  Understanding of analytics roles and responsib...  \n",
       "2317  Engineers collaborate across departments with ...  \n",
       "2318  The team is taking a concept that they’ve used...  \n",
       "2319  Data Scientists and Quantitative Researchers. ...  \n",
       "2320  Insights & Data. (big data, enterprise content...  "
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.reset_index of                                                   Title  \\\n",
       "0                                          STATISTICIAN   \n",
       "1                                        Data Scientist   \n",
       "2                        Disaster Recovery Data Analyst   \n",
       "3                               Data Science Internship   \n",
       "4                                  Quantitative Analyst   \n",
       "5                             Bike Share Data Scientist   \n",
       "6                           Manager of Statistical Data   \n",
       "7                             Junior Research Scientist   \n",
       "8                               Senior Research Analyst   \n",
       "9                                    Sr. Data Scientist   \n",
       "10                                Research Data Manager   \n",
       "11                                         Statistician   \n",
       "12                                  Statistical Analyst   \n",
       "13         Quantitative Primary Market Research Analyst   \n",
       "14                                       Data Scientist   \n",
       "15               Statistical Analyst - Bundled Payments   \n",
       "16                                       Data Scientist   \n",
       "17    2017 Summer Intern - Clinical Analysis - Data ...   \n",
       "18                                 ESG Research Analyst   \n",
       "19                        QA Specialist, Data Scientist   \n",
       "20    Associate Computational Scientist - Oncologica...   \n",
       "21                        Periop Informatics Specialist   \n",
       "22                                 Scientific Associate   \n",
       "23    City Research Scientist, Bureau of the Public ...   \n",
       "24                      Postdoctoral Research Scientist   \n",
       "25                                     Research Analyst   \n",
       "26               Technology Research Analyst (New York)   \n",
       "27                            Partner Success Associate   \n",
       "28                            Machine Learning Engineer   \n",
       "29                                   Sr. Data Scientist   \n",
       "...                                                 ...   \n",
       "2291                          Lead Data Scientist (NLP)   \n",
       "2292  Capital One - Digital Product Manager - Case M...   \n",
       "2293                             Senior DevOps Engineer   \n",
       "2294     Digital Product Manager - Case Management Team   \n",
       "2295  Principal Research Scientist, Clinical Oncolog...   \n",
       "2296                        Java Developer - Northbrook   \n",
       "2297          Data Scientist - Vista Intelligence Group   \n",
       "2298                   Applied Data Scientist - Chicago   \n",
       "2299                              Senior Data Scientist   \n",
       "2300      SVP Quantitative Analyst - Multiple Vacancies   \n",
       "2301                    Machine Learning Data Scientist   \n",
       "2302                              Senior Data Scientist   \n",
       "2303                              Senior Data Scientist   \n",
       "2304  Technical Architect - Cloud Control Tower, McK...   \n",
       "2305                                 Lead Data Engineer   \n",
       "2306  Quantitative Statistical Modeler-Automated Tra...   \n",
       "2307                                     Data Scientist   \n",
       "2308                             Sr. Analytic Developer   \n",
       "2309  Accenture Analytics-Life Science Sales Lead Se...   \n",
       "2310                           Principal Data Scientist   \n",
       "2311                               Chief Credit Officer   \n",
       "2312       Director of Technology - Marketing and Brand   \n",
       "2313                  Head of Machine Learning Big Data   \n",
       "2314                                    Product Manager   \n",
       "2315                                      Product Owner   \n",
       "2316  Analytics Go-To-Market Account Lead, Retail In...   \n",
       "2317                 Senior Engineer - Site Reliability   \n",
       "2318                                    DevOps Engineer   \n",
       "2319       Data Scientists and Quantitative Researchers   \n",
       "2320          Vice President - Global Digital-Analytics   \n",
       "\n",
       "                                          Location City  \\\n",
       "0                                     New York, NY   NY   \n",
       "1                                     New York, NY   NY   \n",
       "2                                     New York, NY   NY   \n",
       "3      New York, NY 10003 (Greenwich Village area)   NY   \n",
       "4                                     New York, NY   NY   \n",
       "5                                    Manhattan, NY   NY   \n",
       "6                                    Manhattan, NY   NY   \n",
       "7                                     New York, NY   NY   \n",
       "8                                     New York, NY   NY   \n",
       "9                                     New York, NY   NY   \n",
       "10                                    New York, NY   NY   \n",
       "11               New York, NY 10001 (Chelsea area)   NY   \n",
       "12                                    New York, NY   NY   \n",
       "13                                   Montclair, NJ   NY   \n",
       "14                                    New York, NY   NY   \n",
       "15                                   Manhattan, NY   NY   \n",
       "16                                    New York, NY   NY   \n",
       "17                                    New York, NY   NY   \n",
       "18    New York, NY 10007 (Financial District area)   NY   \n",
       "19          New York, NY 10012 (Little Italy area)   NY   \n",
       "20             New York, NY 10029 (Yorkville area)   NY   \n",
       "21                                    New York, NY   NY   \n",
       "22                                    New York, NY   NY   \n",
       "23                                   Manhattan, NY   NY   \n",
       "24                                    New York, NY   NY   \n",
       "25                                    New York, NY   NY   \n",
       "26               New York, NY 10011 (Chelsea area)   NY   \n",
       "27                                    New York, NY   NY   \n",
       "28              New York, NY 10016 (Gramercy area)   NY   \n",
       "29                                    New York, NY   NY   \n",
       "...                                            ...  ...   \n",
       "2291                                   Chicago, IL  CHI   \n",
       "2292                           Rolling Meadows, IL  CHI   \n",
       "2293                                   Chicago, IL  CHI   \n",
       "2294                           Rolling Meadows, IL  CHI   \n",
       "2295                               Abbott Park, IL  CHI   \n",
       "2296                                Northbrook, IL  CHI   \n",
       "2297                                   Chicago, IL  CHI   \n",
       "2298                                   Chicago, IL  CHI   \n",
       "2299                 Chicago, IL 60601 (Loop area)  CHI   \n",
       "2300                                   Chicago, IL  CHI   \n",
       "2301                 Chicago, IL 60604 (Loop area)  CHI   \n",
       "2302                                   Chicago, IL  CHI   \n",
       "2303                                   Chicago, IL  CHI   \n",
       "2304                                   Chicago, IL  CHI   \n",
       "2305                                   Chicago, IL  CHI   \n",
       "2306                                   Chicago, IL  CHI   \n",
       "2307                                  Evanston, IL  CHI   \n",
       "2308       Chicago, IL 60661 (Near West Side area)  CHI   \n",
       "2309                                   Chicago, IL  CHI   \n",
       "2310                        Bloomingdale, IL 60108  CHI   \n",
       "2311                                   Chicago, IL  CHI   \n",
       "2312                                   Chicago, IL  CHI   \n",
       "2313                                   Chicago, IL  CHI   \n",
       "2314                                   Chicago, IL  CHI   \n",
       "2315                           Rolling Meadows, IL  CHI   \n",
       "2316                                   Chicago, IL  CHI   \n",
       "2317                                   Chicago, IL  CHI   \n",
       "2318                            Evanston, IL 60201  CHI   \n",
       "2319                                   Chicago, IL  CHI   \n",
       "2320                                   Chicago, IL  CHI   \n",
       "\n",
       "                                                Company Salary_Range  \\\n",
       "0                                        United Nations      61k-80k   \n",
       "1                                           Rodale Inc.      61k-80k   \n",
       "2                                     ICF International      61k-80k   \n",
       "3                                               Knewton      61k-80k   \n",
       "4                                       HARITA INFOTECH      61k-80k   \n",
       "5                          DEPARTMENT OF TRANSPORTATION      61k-80k   \n",
       "6                          DEPT OF INFO TECH & TELECOMM      61k-80k   \n",
       "7                                   New York University      61k-80k   \n",
       "8                          Univision communications inc      61k-80k   \n",
       "9                               Oliver James Associates      61k-80k   \n",
       "10                                      Springer Nature      61k-80k   \n",
       "11                                             Amyx Inc      61k-80k   \n",
       "12                         Hospital for Special Surgery      61k-80k   \n",
       "13                     Medical Marketing Economics, LLC      61k-80k   \n",
       "14                                            W2O Group      61k-80k   \n",
       "15                   Visiting Nurse Service of New York      61k-80k   \n",
       "16                                     Crisis Text Line      61k-80k   \n",
       "17                                          Healthfirst      61k-80k   \n",
       "18                                            MSCI Inc.      61k-80k   \n",
       "19                                                   L2      61k-80k   \n",
       "20                            Mount Sinai Health System      61k-80k   \n",
       "21                           NYU Langone Medical Center      61k-80k   \n",
       "22                                    Sudler& Hennessey      61k-80k   \n",
       "23                        DEPT OF HEALTH/MENTAL HYGIENE      61k-80k   \n",
       "24            Columbia University Medical Center- De...      61k-80k   \n",
       "25                                               GroupM      61k-80k   \n",
       "26                                            Accenture      61k-80k   \n",
       "27                                                Climb      61k-80k   \n",
       "28                             FactSet Research Systems      61k-80k   \n",
       "29                                         Wade & Wendy      61k-80k   \n",
       "...                                                 ...          ...   \n",
       "2291                              Workbridge Associates    121k-140k   \n",
       "2292                    Illinois Technology Association    121k-140k   \n",
       "2293                              Strategic IT Staffing    121k-140k   \n",
       "2294                                        Capital One    121k-140k   \n",
       "2295                              Ascent Services Group    121k-140k   \n",
       "2296                                      TransTech LLC    121k-140k   \n",
       "2297                             Vista Consulting Group    141k-160k   \n",
       "2298                                    Civis Analytics    141k-160k   \n",
       "2299                              Workbridge Associates    141k-160k   \n",
       "2300                                     Selby Jennings    141k-160k   \n",
       "2301                                  Wolverine Trading    141k-160k   \n",
       "2302                                     Selby Jennings    141k-160k   \n",
       "2303                                 Jobspring Partners    141k-160k   \n",
       "2304                                 McKinsey & Company    141k-160k   \n",
       "2305                                    Civis Analytics    141k-160k   \n",
       "2306                                Analytic Recruiting    141k-160k   \n",
       "2307                                           Hirewell    141k-160k   \n",
       "2308                                         TransUnion    141k-160k   \n",
       "2309                                          Accenture    141k-160k   \n",
       "2310                              Workbridge Associates    141k-160k   \n",
       "2311                                             Bolstr    141k-160k   \n",
       "2312                                        Morningstar    141k-160k   \n",
       "2313                                   All-In Analytics    141k-160k   \n",
       "2314                                    Aquent Staffing    141k-160k   \n",
       "2315                Fahrenheit IT Staffing & Consulting    141k-160k   \n",
       "2316                                          Accenture    141k-160k   \n",
       "2317                                    Civis Analytics    141k-160k   \n",
       "2318                                 Jobspring Partners    141k-160k   \n",
       "2319                                            Optiver    161k-180k   \n",
       "2320                                          Capgemini    161k-180k   \n",
       "\n",
       "      Salary_Avg                                            Summary  \n",
       "0           70.5  Organizes, designs, plans and carries out the ...  \n",
       "1           70.5  Query & analyze data:. Data analysis, visualiz...  \n",
       "2           70.5  Disaster Recovery Data Analyst. Organize data ...  \n",
       "3           70.5  You will join a world-class team of data scien...  \n",
       "4           70.5  Looking for a Financial Modelling & Forecastin...  \n",
       "5           70.5  Establish and monitor best practices, policies...  \n",
       "6           70.5  Create data visualizations to communicate comp...  \n",
       "7           70.5  Junior Research Scientist Positions*. The five...  \n",
       "8           70.5  Univision’s Corporate Research is one of the l...  \n",
       "9           70.5  Assist in the on-going efforts to develop data...  \n",
       "10          70.5  Excellent understanding of research data metad...  \n",
       "11          70.5  5 or more years experience with data migration...  \n",
       "12          70.5  Build and improve on Macros to make data proce...  \n",
       "13          70.5  Oversee data collection and address any questi...  \n",
       "14          70.5  We are looking for a Data Scientist to join ou...  \n",
       "15          70.5  Retrieves and compiles data from external data...  \n",
       "16          70.5  Chief Data Scientist. The Data Scientist's rol...  \n",
       "17          70.5  We’re looking for someone with great energy to...  \n",
       "18          70.5  In addition to possessing excellent communicat...  \n",
       "19          70.5  Data dictionary, organizational data model. Me...  \n",
       "20          70.5  Their computational and data workflow. Works w...  \n",
       "21          70.5  Gathers the required preference card supportin...  \n",
       "22          70.5  Referencing all developed content from peer-re...  \n",
       "23          70.5  -Assist with Data Analysis. Two years as a Cit...  \n",
       "24          70.5  Candidates with a MD and/or PhD degree and exp...  \n",
       "25          70.5  DEPARTMENT DESCRIPTION: GroupM Research We are...  \n",
       "26          70.5  Organization: Corporate Functions/Research Loc...  \n",
       "27          70.5  We've started out by funding students at codin...  \n",
       "28          70.5  The primary responsibility for this position w...  \n",
       "29          70.5  Our data scientist will integrate data from we...  \n",
       "...          ...                                                ...  \n",
       "2291       130.5  Hiring for a Lead Data Scientist with a strong...  \n",
       "2292       130.5  They lead teams of designers, engineers, data ...  \n",
       "2293       130.5  Doing all this with an exceptional group of so...  \n",
       "2294       130.5  They lead teams of designers, engineers, data ...  \n",
       "2295       130.5  Principal Research Scientist, Clinical Oncolog...  \n",
       "2296       130.5  Responsible for using strong analytical skills...  \n",
       "2297       150.5  Vista Intelligence Group (VIG) is looking for ...  \n",
       "2298       150.5  Applied data scientists structure hard problem...  \n",
       "2299       150.5  A major Marketing company based in downtown Ch...  \n",
       "2300       150.5  A Top Tier Investment Bank is looking for an e...  \n",
       "2301       150.5  Machine Learning Data Scientist. You will be u...  \n",
       "2302       150.5  Senior Data Scientist | Management Consulting ...  \n",
       "2303       150.5  The ideal person needs to be a personable and ...  \n",
       "2304       150.5  As one of the fastest-growing parts of our fir...  \n",
       "2305       150.5  Survey data, consumer data, public data, and c...  \n",
       "2306       150.5  A Proprietary trading firm in Chicago is looki...  \n",
       "2307       150.5  Data skills, whether relating to data size, sp...  \n",
       "2308       150.5  This position is responsible for developing an...  \n",
       "2309       150.5  Understanding of analytics roles and responsib...  \n",
       "2310       150.5  This candidate will be joining growing team of...  \n",
       "2311       150.5  Excited to use your experience to build a cred...  \n",
       "2312       150.5  Provide visionary technology leadership, keepi...  \n",
       "2313       150.5  Looking for a seasoned manager very strong in ...  \n",
       "2314       150.5  They lead teams of designers, engineers, data ...  \n",
       "2315       150.5  They lead teams of designers, engineers, data ...  \n",
       "2316       150.5  Understanding of analytics roles and responsib...  \n",
       "2317       150.5  Engineers collaborate across departments with ...  \n",
       "2318       150.5  The team is taking a concept that they’ve used...  \n",
       "2319       170.5  Data Scientists and Quantitative Researchers. ...  \n",
       "2320       170.5  Insights & Data. (big data, enterprise content...  \n",
       "\n",
       "[2321 rows x 7 columns]>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,pd.get_dummies(df.City)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>HOU</th>\n",
       "      <th>NY</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATISTICIAN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Organizes, designs, plans and carries out the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rodale Inc.</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Query &amp; analyze data:. Data analysis, visualiz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Title      Location City                 Company Salary_Range  \\\n",
       "0    STATISTICIAN  New York, NY   NY          United Nations      61k-80k   \n",
       "1  Data Scientist  New York, NY   NY             Rodale Inc.      61k-80k   \n",
       "\n",
       "   Salary_Avg                                            Summary  BOS  CHI  \\\n",
       "0        70.5  Organizes, designs, plans and carries out the ...  0.0  0.0   \n",
       "1        70.5  Query & analyze data:. Data analysis, visualiz...  0.0  0.0   \n",
       "\n",
       "    DC  HOU   NY   SF  \n",
       "0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "df.to_csv('indeed_salaries.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('indeed_salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>HOU</th>\n",
       "      <th>NY</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>STATISTICIAN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Organizes, designs, plans and carries out the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rodale Inc.</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Query &amp; analyze data:. Data analysis, visualiz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Disaster Recovery Data Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>ICF International</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Disaster Recovery Data Analyst. Organize data ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           Title      Location City  \\\n",
       "0           0                    STATISTICIAN  New York, NY   NY   \n",
       "1           1                  Data Scientist  New York, NY   NY   \n",
       "2           2  Disaster Recovery Data Analyst  New York, NY   NY   \n",
       "\n",
       "                     Company Salary_Range  Salary_Avg  \\\n",
       "0             United Nations      61k-80k        70.5   \n",
       "1                Rodale Inc.      61k-80k        70.5   \n",
       "2          ICF International      61k-80k        70.5   \n",
       "\n",
       "                                             Summary  BOS  CHI   DC  HOU   NY  \\\n",
       "0  Organizes, designs, plans and carries out the ...  0.0  0.0  0.0  0.0  1.0   \n",
       "1  Query & analyze data:. Data analysis, visualiz...  0.0  0.0  0.0  0.0  1.0   \n",
       "2  Disaster Recovery Data Analyst. Organize data ...  0.0  0.0  0.0  0.0  1.0   \n",
       "\n",
       "    SF  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>HOU</th>\n",
       "      <th>NY</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Evanston, IL 60201</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>141k-160k</td>\n",
       "      <td>150.5</td>\n",
       "      <td>The team is taking a concept that they’ve used...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>Data Scientists and Quantitative Researchers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Optiver</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Data Scientists and Quantitative Researchers. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>Vice President - Global Digital-Analytics</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Insights &amp; Data. (big data, enterprise content...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title            Location City  \\\n",
       "2318                               DevOps Engineer  Evanston, IL 60201  CHI   \n",
       "2319  Data Scientists and Quantitative Researchers         Chicago, IL  CHI   \n",
       "2320     Vice President - Global Digital-Analytics         Chicago, IL  CHI   \n",
       "\n",
       "                         Company Salary_Range  Salary_Avg  \\\n",
       "2318          Jobspring Partners    141k-160k       150.5   \n",
       "2319                     Optiver    161k-180k       170.5   \n",
       "2320                   Capgemini    161k-180k       170.5   \n",
       "\n",
       "                                                Summary  BOS  CHI   DC  HOU  \\\n",
       "2318  The team is taking a concept that they’ve used...  0.0  1.0  0.0  0.0   \n",
       "2319  Data Scientists and Quantitative Researchers. ...  0.0  1.0  0.0  0.0   \n",
       "2320  Insights & Data. (big data, enterprise content...  0.0  1.0  0.0  0.0   \n",
       "\n",
       "       NY   SF  \n",
       "2318  0.0  0.0  \n",
       "2319  0.0  0.0  \n",
       "2320  0.0  0.0  "
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.282608696\n"
     ]
    }
   ],
   "source": [
    "bos_salary = df[df.BOS==1].Salary_Avg.mean()\n",
    "print bos_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.813390313\n"
     ]
    }
   ],
   "source": [
    "chi_salary = df[df.CHI==1].Salary_Avg.mean()\n",
    "print chi_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.439393939\n"
     ]
    }
   ],
   "source": [
    "dc_salary = df[df.DC==1].Salary_Avg.mean()\n",
    "print dc_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.5\n"
     ]
    }
   ],
   "source": [
    "hou_salary = df[df.HOU==1].Salary_Avg.mean()\n",
    "print hou_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.202702703\n"
     ]
    }
   ],
   "source": [
    "ny_salary = df[df.NY==1].Salary_Avg.mean()\n",
    "print ny_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.804347826\n"
     ]
    }
   ],
   "source": [
    "sf_salary = df[df.SF==1].Salary_Avg.mean()\n",
    "print sf_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choice the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.303102111\n"
     ]
    }
   ],
   "source": [
    "mean_salary = np.mean(df.Salary_Avg)\n",
    "print mean_salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.5"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(df.Salary_Avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapping salary ranges\n",
    "\n",
    "    0 if below the median\n",
    "    1 if equal to or above the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Above_Median'] = df['Salary_Range'].map({'61k-80k':0,'81k-100k':0,'101k-120k':1, '121k-140k':1, '141k-160k':1, '161k-180k':1, '181k:200k':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1289\n",
       "0.0    1031\n",
       "Name: Above_Median, dtype: int64"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Above_Median'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>HOU</th>\n",
       "      <th>NY</th>\n",
       "      <th>SF</th>\n",
       "      <th>Above_Median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>Data Scientists and Quantitative Researchers</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Optiver</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Data Scientists and Quantitative Researchers. ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>Vice President - Global Digital-Analytics</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>161k-180k</td>\n",
       "      <td>170.5</td>\n",
       "      <td>Insights &amp; Data. (big data, enterprise content...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Title     Location City  \\\n",
       "2319  Data Scientists and Quantitative Researchers  Chicago, IL  CHI   \n",
       "2320     Vice President - Global Digital-Analytics  Chicago, IL  CHI   \n",
       "\n",
       "                Company Salary_Range  Salary_Avg  \\\n",
       "2319            Optiver    161k-180k       170.5   \n",
       "2320          Capgemini    161k-180k       170.5   \n",
       "\n",
       "                                                Summary  BOS  CHI   DC  HOU  \\\n",
       "2319  Data Scientists and Quantitative Researchers. ...  0.0  1.0  0.0  0.0   \n",
       "2320  Insights & Data. (big data, enterprise content...  0.0  1.0  0.0  0.0   \n",
       "\n",
       "       NY   SF  Above_Median  \n",
       "2319  0.0  0.0           1.0  \n",
       "2320  0.0  0.0           1.0  "
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_metrics(model, X_train,y_train,y_test,y_pred):\n",
    "    crossvalscore = cross_val_score(model, X_train, y_train).mean()\n",
    "    accuracyscore = accuracy_score(y_test,y_pred)\n",
    "    classificationreport = classification_report(y_test,y_pred)\n",
    "    confusionmatrix = confusion_matrix(y_test,y_pred)\n",
    "    print 'Cross_Val_Score: ' + str(crossvalscore) + '\\n'\n",
    "    print 'Accuracy_Score: ' + str(accuracyscore) + '\\n'\n",
    "    print 'Classification_Report: \\n', str(classificationreport)+ '\\n'\n",
    "    print 'Confusion_Matrix: ' + '\\n' + str(confusionmatrix) + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Above_Median == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.Above_Median == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5559878945092953"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1286.0/(1027+1286)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy of my model is 56% because my greatest class (= or > the median) contains 56% of my points. Thus, if I guessed that class every time, I could score 56%. For this reason, my model must perform better than 56% to have any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Using Cities Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_city = df[['BOS', 'CHI','DC','HOU','NY','SF']].apply(LabelEncoder().fit_transform)\n",
    "y_city = le.fit_transform(df['Above_Median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_city,X_test_city,y_train_city,y_test_city = train_test_split(X_city,y_city,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.582171536421\n",
      "\n",
      "Accuracy_Score: 0.555938037866\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.21      0.29       256\n",
      "          1       0.57      0.83      0.68       325\n",
      "\n",
      "avg / total       0.54      0.56      0.51       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[ 53 203]\n",
      " [ 55 270]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_city,y_train_city)\n",
    "rfc_pred_city = rfc.predict(X_test_city)\n",
    "\n",
    "run_metrics(rfc, X_train_city,y_train_city,y_test_city, rfc_pred_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "Let's try treating this as a regression problem. \n",
    "\n",
    "- Train a random forest regressor on the regression problem and predict your dependent.\n",
    "- Evaluate the score with a 5-fold cross-validation\n",
    "- Do a scatter plot of the predicted vs actual scores for each of the 5 folds, do they match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_reg = df[['BOS', 'CHI','DC','HOU','NY','SF']].apply(le.fit_transform)\n",
    "y_reg = le.fit_transform(df['Salary_Avg'])\n",
    "\n",
    "X_train_reg,X_test_reg,y_train_reg,y_test_reg = train_test_split(X_reg,y_reg,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0367509500432\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train_reg,y_train_reg)\n",
    "rfr_pred = rfr.predict(X_test_reg)\n",
    "print cross_val_score(rfr, X_train_reg, y_train_reg).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(df.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "df_nlp_summary = pd.DataFrame(cvec.transform(df.Summary).todense(),\n",
    "             columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1010data</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>12</th>\n",
       "      <th>12066</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>yume</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoomdata</th>\n",
       "      <th>企业不同</th>\n",
       "      <th>但跟大多数consulting</th>\n",
       "      <th>全球范围内员工超过2500人</th>\n",
       "      <th>在科技服务方面成军20年</th>\n",
       "      <th>虽然对于国际学生部分都是consulting业务</th>\n",
       "      <th>ﬁll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  04  10  100  1000  1010data  11  110  12  12066 ...   younger  yume  \\\n",
       "0    0   0   0    0     0         0   0    0   0      0 ...         0     0   \n",
       "1    0   0   0    0     0         0   0    0   0      0 ...         0     0   \n",
       "\n",
       "   zero  zoomdata  企业不同  但跟大多数consulting  全球范围内员工超过2500人  在科技服务方面成军20年  \\\n",
       "0     0         0     0                0               0             0   \n",
       "1     0         0     0                0               0             0   \n",
       "\n",
       "   虽然对于国际学生部分都是consulting业务  ﬁll  \n",
       "0                         0    0  \n",
       "1                         0    0  \n",
       "\n",
       "[2 rows x 4214 columns]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_summary.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>selecting</th>\n",
       "      <th>evaluation</th>\n",
       "      <th>plans</th>\n",
       "      <th>methods</th>\n",
       "      <th>data</th>\n",
       "      <th>designs</th>\n",
       "      <th>dissemination</th>\n",
       "      <th>carries</th>\n",
       "      <th>organizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2304</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2321 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      collection  selecting  evaluation  plans  methods  data  designs  \\\n",
       "0              1          1           1      1        1     1        1   \n",
       "1              0          0           0      0        0     3        0   \n",
       "2              0          0           0      0        0     3        0   \n",
       "3              0          0           0      0        0     1        0   \n",
       "4              0          0           0      0        0     0        0   \n",
       "5              0          0           0      0        0     2        0   \n",
       "6              0          0           0      0        0     2        0   \n",
       "7              0          0           0      0        0     0        0   \n",
       "8              0          0           0      0        0     0        0   \n",
       "9              0          0           0      0        0     3        0   \n",
       "10             0          0           0      0        0     3        0   \n",
       "11             0          0           0      0        0     3        0   \n",
       "12             0          0           0      0        0     2        0   \n",
       "13             2          0           0      0        0     3        0   \n",
       "14             0          0           0      0        0     2        0   \n",
       "15             0          0           0      0        0     3        0   \n",
       "16             0          0           0      0        0     3        0   \n",
       "17             0          0           0      0        0     1        0   \n",
       "18             0          0           0      0        0     1        0   \n",
       "19             0          0           0      0        0     4        0   \n",
       "20             0          0           0      0        0     1        0   \n",
       "21             0          0           0      0        0     3        0   \n",
       "22             0          0           0      0        0     1        0   \n",
       "23             0          0           0      0        0     1        0   \n",
       "24             0          0           0      0        0     2        0   \n",
       "25             0          0           0      0        0     0        0   \n",
       "26             0          0           0      0        0     0        0   \n",
       "27             0          0           0      0        0     0        0   \n",
       "28             0          0           0      0        0     0        0   \n",
       "29             0          0           0      0        0     2        0   \n",
       "...          ...        ...         ...    ...      ...   ...      ...   \n",
       "2291           0          0           0      0        0     2        0   \n",
       "2292           0          0           0      0        0     1        0   \n",
       "2293           0          0           0      0        0     1        0   \n",
       "2294           0          0           0      0        0     1        0   \n",
       "2295           0          0           0      0        0     1        0   \n",
       "2296           0          0           0      0        0     1        0   \n",
       "2297           0          0           0      0        0     2        0   \n",
       "2298           0          0           0      0        0     2        0   \n",
       "2299           0          0           0      0        0     2        0   \n",
       "2300           0          0           0      0        0     0        0   \n",
       "2301           0          0           0      0        0     3        0   \n",
       "2302           0          0           0      0        0     2        0   \n",
       "2303           0          0           0      0        0     4        0   \n",
       "2304           0          0           0      0        0     1        0   \n",
       "2305           0          0           0      0        0     6        0   \n",
       "2306           0          0           0      0        0     0        0   \n",
       "2307           0          0           0      0        0     3        0   \n",
       "2308           0          0           0      0        0     1        0   \n",
       "2309           0          0           0      0        0     2        0   \n",
       "2310           0          0           0      0        0     1        0   \n",
       "2311           0          0           0      0        0     1        0   \n",
       "2312           0          0           0      0        0     0        0   \n",
       "2313           0          0           0      0        0     2        0   \n",
       "2314           0          0           0      0        0     1        0   \n",
       "2315           0          0           0      0        0     1        0   \n",
       "2316           0          0           0      0        0     1        0   \n",
       "2317           0          0           0      0        0     1        0   \n",
       "2318           0          0           0      0        0     1        0   \n",
       "2319           0          0           0      0        0     2        0   \n",
       "2320           0          0           0      0        0     3        0   \n",
       "\n",
       "      dissemination  carries  organizes  \n",
       "0                 1        1          1  \n",
       "1                 0        0          0  \n",
       "2                 0        0          0  \n",
       "3                 0        0          0  \n",
       "4                 0        0          0  \n",
       "5                 0        0          0  \n",
       "6                 0        0          0  \n",
       "7                 0        0          0  \n",
       "8                 0        0          0  \n",
       "9                 0        0          0  \n",
       "10                0        0          0  \n",
       "11                0        0          0  \n",
       "12                0        0          0  \n",
       "13                0        0          0  \n",
       "14                0        0          0  \n",
       "15                0        0          0  \n",
       "16                0        0          0  \n",
       "17                0        0          0  \n",
       "18                0        0          0  \n",
       "19                0        0          0  \n",
       "20                0        0          0  \n",
       "21                0        0          0  \n",
       "22                0        0          0  \n",
       "23                0        0          0  \n",
       "24                0        0          0  \n",
       "25                0        0          0  \n",
       "26                0        0          0  \n",
       "27                0        0          0  \n",
       "28                0        0          0  \n",
       "29                0        0          0  \n",
       "...             ...      ...        ...  \n",
       "2291              0        0          0  \n",
       "2292              0        0          0  \n",
       "2293              0        0          0  \n",
       "2294              0        0          0  \n",
       "2295              0        0          0  \n",
       "2296              0        0          0  \n",
       "2297              0        0          0  \n",
       "2298              0        0          0  \n",
       "2299              0        0          0  \n",
       "2300              0        0          0  \n",
       "2301              0        0          0  \n",
       "2302              0        0          0  \n",
       "2303              0        0          0  \n",
       "2304              0        0          0  \n",
       "2305              0        0          0  \n",
       "2306              0        0          0  \n",
       "2307              0        0          0  \n",
       "2308              0        0          0  \n",
       "2309              0        0          0  \n",
       "2310              0        0          0  \n",
       "2311              0        0          0  \n",
       "2312              0        0          0  \n",
       "2313              0        0          0  \n",
       "2314              0        0          0  \n",
       "2315              0        0          0  \n",
       "2316              0        0          0  \n",
       "2317              0        0          0  \n",
       "2318              0        0          0  \n",
       "2319              0        0          0  \n",
       "2320              0        0          0  \n",
       "\n",
       "[2321 rows x 10 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_summary.transpose().sort_values(0, ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                 4115\n",
       "scientist             823\n",
       "scientists            613\n",
       "experience            407\n",
       "analysis              380\n",
       "team                  376\n",
       "research              288\n",
       "work                  250\n",
       "science               236\n",
       "analytics             222\n",
       "engineers             199\n",
       "learning              181\n",
       "machine               178\n",
       "looking               176\n",
       "big                   174\n",
       "working               163\n",
       "senior                152\n",
       "new                   150\n",
       "statistical           146\n",
       "management            146\n",
       "join                  142\n",
       "seeking               139\n",
       "business              135\n",
       "large                 134\n",
       "develop               129\n",
       "software              124\n",
       "using                 119\n",
       "sets                  117\n",
       "including             113\n",
       "analyst               113\n",
       "                     ... \n",
       "exceptions              1\n",
       "preferable              1\n",
       "estimates               1\n",
       "estimation              1\n",
       "et                      1\n",
       "priority                1\n",
       "ethical                 1\n",
       "ethos                   1\n",
       "prioritizing            1\n",
       "prioritize              1\n",
       "priorities              1\n",
       "evaluated               1\n",
       "primitives              1\n",
       "prime                   1\n",
       "pride                   1\n",
       "prevention              1\n",
       "president               1\n",
       "events                  1\n",
       "prescriptive            1\n",
       "evidencing              1\n",
       "evoke                   1\n",
       "prescribewellness       1\n",
       "ex                      1\n",
       "examine                 1\n",
       "examples                1\n",
       "prepared                1\n",
       "excellence              1\n",
       "exception               1\n",
       "preference              1\n",
       "j3                      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nlp_summary.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with No Cities and Hand Selected NLP Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_nlp = df_nlp_summary[['junior', 'senior', 'manager', 'masters', 'phd', 'entry', 'scientist', 'machine','research','software']].apply(le.fit_transform)\n",
    "y_nlp = le.fit_transform(df['Above_Median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_nlp,X_test_nlp,y_train_nlp,y_test_nlp = train_test_split(X_nlp,y_nlp,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.58048299889\n",
      "\n",
      "Accuracy_Score: 0.60413080895\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.74      0.62       256\n",
      "          1       0.71      0.50      0.58       325\n",
      "\n",
      "avg / total       0.63      0.60      0.60       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[189  67]\n",
      " [163 162]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_nlp,y_train_nlp)\n",
    "rfc_pred_nlp = rfc.predict(X_test_nlp)\n",
    "\n",
    "run_metrics(rfc, X_train_nlp,y_train_nlp,y_test_nlp, rfc_pred_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df,df_nlp_summary],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>yume</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoomdata</th>\n",
       "      <th>企业不同</th>\n",
       "      <th>但跟大多数consulting</th>\n",
       "      <th>全球范围内员工超过2500人</th>\n",
       "      <th>在科技服务方面成军20年</th>\n",
       "      <th>虽然对于国际学生部分都是consulting业务</th>\n",
       "      <th>ﬁll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STATISTICIAN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Organizes, designs, plans and carries out the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rodale Inc.</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Query &amp; analyze data:. Data analysis, visualiz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disaster Recovery Data Analyst</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>ICF International</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Disaster Recovery Data Analyst. Organize data ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 4228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title      Location City  \\\n",
       "0                    STATISTICIAN  New York, NY   NY   \n",
       "1                  Data Scientist  New York, NY   NY   \n",
       "2  Disaster Recovery Data Analyst  New York, NY   NY   \n",
       "\n",
       "                     Company Salary_Range  Salary_Avg  \\\n",
       "0             United Nations      61k-80k        70.5   \n",
       "1                Rodale Inc.      61k-80k        70.5   \n",
       "2          ICF International      61k-80k        70.5   \n",
       "\n",
       "                                             Summary  BOS  CHI   DC ...   \\\n",
       "0  Organizes, designs, plans and carries out the ...  0.0  0.0  0.0 ...    \n",
       "1  Query & analyze data:. Data analysis, visualiz...  0.0  0.0  0.0 ...    \n",
       "2  Disaster Recovery Data Analyst. Organize data ...  0.0  0.0  0.0 ...    \n",
       "\n",
       "   younger  yume  zero  zoomdata  企业不同  但跟大多数consulting  全球范围内员工超过2500人  \\\n",
       "0        0     0     0         0     0                0               0   \n",
       "1        0     0     0         0     0                0               0   \n",
       "2        0     0     0         0     0                0               0   \n",
       "\n",
       "   在科技服务方面成军20年  虽然对于国际学生部分都是consulting业务  ﬁll  \n",
       "0             0                         0    0  \n",
       "1             0                         0    0  \n",
       "2             0                         0    0  \n",
       "\n",
       "[3 rows x 4228 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with Cities and Hand Selected NLP Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_choice = df_all[['Title','BOS','CHI','DC','HOU','NY','SF','junior', 'senior', 'masters', 'phd', 'entry', 'scientist', 'machine']].apply(LabelEncoder().fit_transform)\n",
    "y_choice = le.fit_transform(df_all['Above_Median'])\n",
    "X_train_choice,X_test_choice,y_train_choice,y_test_choice = train_test_split(X_choice,y_choice,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.639086231149\n",
      "\n",
      "Accuracy_Score: 0.638554216867\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.65      0.61       256\n",
      "          1       0.70      0.63      0.66       325\n",
      "\n",
      "avg / total       0.64      0.64      0.64       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[167  89]\n",
      " [121 204]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_choice,y_train_choice)\n",
    "rfc_pred_choice = rfc.predict(X_test_choice)\n",
    "\n",
    "run_metrics(rfc, X_train_choice,y_train_choice,y_test_choice, rfc_pred_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = df_all.drop(['Above_Median','Salary_Range','Salary_Avg'], axis=1).apply(LabelEncoder().fit_transform)\n",
    "y_all = le.fit_transform(df_all['Above_Median'])\n",
    "X_train_all,X_test_all,y_train_all,y_test_all = train_test_split(X_all,y_all,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_all,y_train_all)\n",
    "rfc_pred_all = rfc.predict(X_test_all)\n",
    "score = cross_val_score(rfc, X_train_all, y_train_all).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.650609238585\n",
      "\n",
      "Accuracy_Score: 0.719449225473\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.67      0.68       256\n",
      "          1       0.74      0.76      0.75       325\n",
      "\n",
      "avg / total       0.72      0.72      0.72       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[171  85]\n",
      " [ 78 247]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_metrics(rfc, X_train_all,y_train_all,y_test_all, rfc_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with NLP on Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(df.Title)\n",
    "df_nlp_Title = pd.DataFrame(cvec.transform(df.Summary).todense(),\n",
    "             columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_title = df_nlp_Title.apply(LabelEncoder().fit_transform)\n",
    "y_title = le.fit_transform(df_all['Above_Median'])\n",
    "X_train_title,X_test_title,y_train_title,y_test_title = train_test_split(X_title,y_title,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.664927680739\n",
      "\n",
      "Accuracy_Score: 0.717728055077\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.70      0.69       256\n",
      "          1       0.76      0.73      0.74       325\n",
      "\n",
      "avg / total       0.72      0.72      0.72       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[179  77]\n",
      " [ 87 238]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_jobs=-1)\n",
    "rfc.fit(X_train_title,y_train_title)\n",
    "rfc_pred_title = rfc.predict(X_test_title)\n",
    "\n",
    "run_metrics(rfc,X_train_title,y_train_title, y_test_title,rfc_pred_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Summary CVEC and City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = df_all.drop(['Above_Median','Salary_Range','Salary_Avg'], axis=1).apply(LabelEncoder().fit_transform)\n",
    "y_all = le.fit_transform(df_all['Above_Median'])\n",
    "X_train_all,X_test_all,y_train_all,y_test_all = train_test_split(X_all,y_all,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.700051635418\n",
      "\n",
      "Accuracy_Score: 0.73321858864\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.62      0.67       256\n",
      "          1       0.73      0.82      0.78       325\n",
      "\n",
      "avg / total       0.73      0.73      0.73       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[159  97]\n",
      " [ 58 267]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_all,y_train_all)\n",
    "logit_pred_all = logit.predict(X_test_all)\n",
    "\n",
    "run_metrics(logit,X_train_all,y_train_all, y_test_all,logit_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting with City and CVEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.691959118993\n",
      "\n",
      "Accuracy_Score: 0.729776247849\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.61      0.67       256\n",
      "          1       0.73      0.82      0.77       325\n",
      "\n",
      "avg / total       0.73      0.73      0.73       581\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[157  99]\n",
      " [ 58 267]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train_all,y_train_all)\n",
    "gb_pred_all = gb.predict(X_test_all)\n",
    "\n",
    "run_metrics(gb,X_train_all,y_train_all, y_test_all,gb_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              importance\n",
      "compensation    0.099947\n",
      "199             0.087106\n",
      "gaining         0.076913\n",
      "Title           0.058574\n",
      "Company         0.039662\n",
      "data            0.017436\n",
      "Location        0.017388\n",
      "lead            0.010367\n",
      "scientists      0.010307\n",
      "scientist       0.010291\n",
      "analyst         0.010147\n",
      "machine         0.009662\n",
      "senior          0.008827\n",
      "Summary         0.008802\n",
      "interpret       0.008490\n",
      "analytics       0.008254\n",
      "research        0.008116\n",
      "big             0.008059\n",
      "environments    0.007980\n",
      "analysis        0.007890\n",
      "building        0.007428\n",
      "collection      0.007196\n",
      "CHI             0.007024\n",
      "science         0.006613\n",
      "using           0.006214\n",
      "experience      0.006025\n",
      "models          0.005960\n",
      "analyzing       0.005753\n",
      "analyze         0.005702\n",
      "risk            0.005570\n",
      "analysts        0.005436\n",
      "geospatial      0.005297\n",
      "reports         0.005071\n",
      "brand           0.004989\n",
      "implement       0.004814\n"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame(gb.feature_importances_, index=df_all.drop(['Above_Median','Salary_Range','Salary_Avg'],axis=1).columns, columns=['importance'])\n",
    "print features.sort_values(['importance'], ascending=False).head(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>04</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1010data</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>12066</th>\n",
       "      <th>1300</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>yume</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoomdata</th>\n",
       "      <th>企业不同</th>\n",
       "      <th>但跟大多数consulting</th>\n",
       "      <th>全球范围内员工超过2500人</th>\n",
       "      <th>在科技服务方面成军20年</th>\n",
       "      <th>虽然对于国际学生部分都是consulting业务</th>\n",
       "      <th>ﬁll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   04   10  100  1000  1010data   11  110  12066  1300 ...   younger  \\\n",
       "0  0.0  0.0  0.0  0.0   0.0       0.0  0.0  0.0    0.0   0.0 ...       0.0   \n",
       "1  0.0  0.0  0.0  0.0   0.0       0.0  0.0  0.0    0.0   0.0 ...       0.0   \n",
       "2  0.0  0.0  0.0  0.0   0.0       0.0  0.0  0.0    0.0   0.0 ...       0.0   \n",
       "3  0.0  0.0  0.0  0.0   0.0       0.0  0.0  0.0    0.0   0.0 ...       0.0   \n",
       "4  0.0  0.0  0.0  0.0   0.0       0.0  0.0  0.0    0.0   0.0 ...       0.0   \n",
       "\n",
       "   yume  zero  zoomdata  企业不同  但跟大多数consulting  全球范围内员工超过2500人  在科技服务方面成军20年  \\\n",
       "0   0.0   0.0       0.0   0.0              0.0             0.0           0.0   \n",
       "1   0.0   0.0       0.0   0.0              0.0             0.0           0.0   \n",
       "2   0.0   0.0       0.0   0.0              0.0             0.0           0.0   \n",
       "3   0.0   0.0       0.0   0.0              0.0             0.0           0.0   \n",
       "4   0.0   0.0       0.0   0.0              0.0             0.0           0.0   \n",
       "\n",
       "   虽然对于国际学生部分都是consulting业务  ﬁll  \n",
       "0                       0.0  0.0  \n",
       "1                       0.0  0.0  \n",
       "2                       0.0  0.0  \n",
       "3                       0.0  0.0  \n",
       "4                       0.0  0.0  \n",
       "\n",
       "[5 rows x 4213 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit(df.Summary)\n",
    "\n",
    "df_tfidf = pd.DataFrame(tvec.transform(df.Summary).todense(),\n",
    "                   columns=tvec.get_feature_names())\n",
    "\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with TFIDF Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf = df_tfidf.apply(LabelEncoder().fit_transform)\n",
    "y_tfidf = le.fit_transform(df_all['Above_Median'])\n",
    "X_train_tfidf,X_test_tfidf,y_train_tfidf,y_test_tfidf = train_test_split(X_tfidf,y_tfidf,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.681270188249\n",
      "\n",
      "Accuracy_Score: 0.721934369603\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.61      0.66       257\n",
      "          1       0.72      0.81      0.76       322\n",
      "\n",
      "avg / total       0.72      0.72      0.72       579\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[156 101]\n",
      " [ 60 262]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = gb.fit(X_train_tfidf,y_train_tfidf)\n",
    "gb_pred_tfidf = gb.predict(X_test_tfidf)\n",
    "\n",
    "run_metrics(gb,X_train_tfidf,y_train_tfidf, y_test_tfidf,gb_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>City</th>\n",
       "      <th>Company</th>\n",
       "      <th>Salary_Range</th>\n",
       "      <th>Salary_Avg</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Above_Median</th>\n",
       "      <th>BOS</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DC</th>\n",
       "      <th>HOU</th>\n",
       "      <th>NY</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Science</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Corporate Technology</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>JOB DESCRIPTION – DATA SCIENTIST. We're lookin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Research Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York University</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Senior Research Scientist*. The McDevitt lab i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associate Research Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York University</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Associate Research Scientist*. The Data Scient...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>Rodale Inc.</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Query &amp; analyze data:. Data analysis, visualiz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATISTICIAN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NY</td>\n",
       "      <td>United Nations</td>\n",
       "      <td>61k-80k</td>\n",
       "      <td>70.5</td>\n",
       "      <td>Organizes, designs, plans and carries out the ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title      Location City  \\\n",
       "0  Data Scientist / Data Science  New York, NY   NY   \n",
       "1      Senior Research Scientist  New York, NY   NY   \n",
       "2   Associate Research Scientist  New York, NY   NY   \n",
       "3                 Data Scientist  New York, NY   NY   \n",
       "4                   STATISTICIAN  New York, NY   NY   \n",
       "\n",
       "                       Company Salary_Range  Salary_Avg  \\\n",
       "0         Corporate Technology      61k-80k        70.5   \n",
       "1          New York University      61k-80k        70.5   \n",
       "2          New York University      61k-80k        70.5   \n",
       "3                  Rodale Inc.      61k-80k        70.5   \n",
       "4               United Nations      61k-80k        70.5   \n",
       "\n",
       "                                             Summary  Above_Median  BOS  CHI  \\\n",
       "0  JOB DESCRIPTION – DATA SCIENTIST. We're lookin...           0.0  0.0  0.0   \n",
       "1  Senior Research Scientist*. The McDevitt lab i...           0.0  0.0  0.0   \n",
       "2  Associate Research Scientist*. The Data Scient...           0.0  0.0  0.0   \n",
       "3  Query & analyze data:. Data analysis, visualiz...           0.0  0.0  0.0   \n",
       "4  Organizes, designs, plans and carries out the ...           0.0  0.0  0.0   \n",
       "\n",
       "    DC  HOU   NY   SF  \n",
       "0  0.0  0.0  1.0  0.0  \n",
       "1  0.0  0.0  1.0  0.0  \n",
       "2  0.0  0.0  1.0  0.0  \n",
       "3  0.0  0.0  1.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf_city = pd.concat([df,df_tfidf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tfidf_city.drop(['Location','City','Salary_Range','Salary_Avg','Summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting with TFIDF and City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tfidf_city = df_tfidf_city.drop(['Above_Median'], axis=1).apply(LabelEncoder().fit_transform)\n",
    "y_tfidf_city = le.fit_transform(df_tfidf_city['Above_Median'])\n",
    "X_train_tfidfcity,X_test_tfidfcity,y_train_tfidfcity,y_test_tfidfcity = train_test_split(X_tfidf_city,y_tfidf_city,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross_Val_Score: 0.696275436221\n",
      "\n",
      "Accuracy_Score: 0.72884283247\n",
      "\n",
      "Classification_Report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.65      0.68       257\n",
      "          1       0.74      0.80      0.77       322\n",
      "\n",
      "avg / total       0.73      0.73      0.73       579\n",
      "\n",
      "\n",
      "Confusion_Matrix: \n",
      "[[166  91]\n",
      " [ 66 256]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = gb.fit(X_train_tfidfcity,y_train_tfidfcity)\n",
    "gb_pred_tfidfcity = gb.predict(X_test_tfidfcity)\n",
    "\n",
    "run_metrics(gb,X_train_tfidfcity,y_train_tfidfcity, y_test_tfidfcity,gb_pred_tfidfcity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               importance\n",
      "compensation     0.106378\n",
      "gaining          0.074890\n",
      "199              0.071608\n",
      "data             0.038454\n",
      "Title            0.034351\n",
      "Company          0.031081\n",
      "scientists       0.018922\n",
      "science          0.016820\n",
      "analysis         0.013777\n",
      "databases        0.011802\n",
      "research         0.011366\n",
      "analyst          0.010439\n",
      "lead             0.009307\n",
      "analytics        0.009135\n",
      "reports          0.008207\n",
      "analyzing        0.007941\n",
      "risk             0.007921\n",
      "scientist        0.007617\n",
      "senior           0.007484\n",
      "help             0.007431\n",
      "skills           0.007251\n",
      "engineer         0.007226\n",
      "big              0.007172\n",
      "software         0.006847\n",
      "analysts         0.006609\n",
      "building         0.006575\n",
      "quantitative     0.006403\n",
      "generate         0.006400\n",
      "interpret        0.006393\n",
      "understanding    0.006339\n",
      "datasets         0.005927\n",
      "integrate        0.005793\n",
      "environments     0.005661\n",
      "learning         0.005584\n",
      "sequencing       0.004943\n"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame(gb.feature_importances_, index=df_tfidf_city.drop(['Above_Median'],axis=1).columns, columns=['importance'])\n",
    "print features.sort_values(['importance'], ascending=False).head(35)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
